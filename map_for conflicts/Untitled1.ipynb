{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf2e1fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3] 4\n",
      "[2 3 4] 5\n",
      "[3 4 5] 6\n",
      "[4 5 6] 7\n",
      "[5 6 7] 8\n",
      "[6 7 8] 9\n",
      "[7 8 9] 10\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "\n",
    "\n",
    "def split_sequence(sequence,n_steps):\n",
    "    x,y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        end_x  = i + n_steps\n",
    "\n",
    "        # check if we are beyond the sequence\n",
    "        if end_x > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output part\n",
    "        seq_x, seq_y = sequence[i:end_x], sequence[end_x]\n",
    "        x.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(x), array(y)\n",
    "\n",
    "series = array([1,2,3,4,5,6,7,8,9,10])\n",
    "x,y = split_sequence(series,3)\n",
    "for i in range(len(x)):\n",
    "    print(x[i],y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c40b0a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "(7, 3) (7,)\n",
      "(7, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#transform univariate time series to supervised learning problem\n",
    "from numpy import array\n",
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "\n",
    "    return array(X), array(y)\n",
    "# define univariate time series\n",
    "series = array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "print(series.shape)\n",
    "# transform to a supervised learning problem\n",
    "X, y = split_sequence(series, 3)\n",
    "print(X.shape, y.shape)\n",
    "x = x.reshape(x.shape[0],x.shape[1],1)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52b9951",
   "metadata": {},
   "source": [
    "# Consider that you are in the current situation:\n",
    "I have two columns in my data file with 5,000 rows, column 1 is time (with 1 hour\n",
    "interval) and column 2 is the number of sales and I am trying to forecast the number\n",
    "of sales for future time steps. Help me to set the number of samples, time steps and\n",
    "features in this data for an LSTM?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd952810",
   "metadata": {},
   "source": [
    "# We will work through this example, broken down into the following 4 steps:\n",
    "1. Load the Data\n",
    "2. Drop the Time Column\n",
    "3. Split Into Samples\n",
    "4. Reshape Subsequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f38de94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1 10]\n",
      " [ 2 20]\n",
      " [ 3 30]\n",
      " [ 4 40]\n",
      " [ 5 50]]\n",
      "(5000, 2)\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "\n",
    "data = list()\n",
    "n = 5000\n",
    "for i in range(n):\n",
    "    data.append([(i+1),(i+1)*10])\n",
    "data = array(data)\n",
    "print(data[:5, :])\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c318ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000,)\n",
      "25\n",
      "(25, 200)\n",
      "(25, 200, 1)\n"
     ]
    }
   ],
   "source": [
    "# drop the time column\n",
    "data = list()\n",
    "n = 5000\n",
    "for i in range(n):\n",
    "    data.append([(i+1), (1+1)*10])\n",
    "data = array(data)\n",
    "#drop the time column\n",
    "data = data[:,1]\n",
    "print(data.shape) \n",
    "\n",
    "\n",
    "# split our data in 200 time-steps (5000/25 = 200)\n",
    "samples = list()\n",
    "length = 200\n",
    "for i in range(0,n,length):\n",
    "    sample = data[i:i+length]\n",
    "    samples.append(sample)\n",
    "print(len(samples))\n",
    "\n",
    "\n",
    "# converte our sample into 2D\n",
    "data = array(samples)\n",
    "print(data.shape)\n",
    "\n",
    "# adding the feature\n",
    "data = data.reshape(len(samples),length, 1)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6328b06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import plotly.graph_objects as go\n",
    "# import pandas as pd\n",
    "# import geopandas as gpd\n",
    "# import plotly.express as px\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# path = \"/home/adzavon/Documents/MSC_Data_Analysis/conflicts/let_stry.csv\"\n",
    "# conflicts_dataset = pd.read_csv(path,index_col=0,dtype = {\"ccaa_id\": str}, encoding = 'latin-1')\n",
    "# geojson_map = gpd.read_file(\"/home/adzavon/Documents/MSC_Data_Analysis/study area maping/regions.geojson\")\n",
    "# shapefile = gpd.read_file(\"/home/adzavon/Documents/MSC_Data_Analysis/study area maping/gadm36_BFA_shp/gadm36_BFA_shp/gadm36_BFA_1.shp\")\n",
    "# shapefile_map = shapefile[[\"NAME_1\",\"geometry\"]]\n",
    "# merged = shapefile.set_index('NAME_1').join(conflicts_dataset.set_index(\"Region\"))\n",
    "# #merged_file = merged[[\"Year\",\"EVENT_TYPE\",\"SUM_CONFLICTS\",\"geometry\"]]\n",
    "# #merged.head(2)\n",
    "# #merged_file\n",
    "# merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9baa4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # conflicts_dataset.groupby([\"Year\",\"Region\",\"EVENT_TYPE\"]).sum()\n",
    "\n",
    "# fig, ax = plt.subplots(1, figsize=(10,6))\n",
    "# merged_file.plot(column='SUM_CONFLICTS', cmap='Blues', linewidth=1, ax=ax, edgecolor='0.9', legend = True)\n",
    "# ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9556fb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = px.choropleth(merged_file, geojson=merged.geometry, \n",
    "#                     locations=merged_file.index, color=\"SUM_CONFLICTS\",\n",
    "#                     height=500,\n",
    "#                    color_continuous_scale=\"Viridis\")\n",
    "# # fig.update_geos(fitbounds=\"locations\", visible=True)\n",
    "# # fig.update_layout(\n",
    "# #     title_text='Map'\n",
    "# #)\n",
    "# # fig.update(layout = dict(title=dict(x=0.5)))\n",
    "# # fig.update_layout(\n",
    "# #     margin={\"r\":0,\"t\":30,\"l\":10,\"b\":10},\n",
    "# #     coloraxis_colorbar={\n",
    "# #         'title':'Sum'})\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0144f8e3",
   "metadata": {},
   "source": [
    "# Univariate MLP Models\n",
    "\n",
    "Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27192d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 20 30] 40\n",
      "[20 30 40] 50\n",
      "[30 40 50] 60\n",
      "[40 50 60] 70\n",
      "[50 60 70] 80\n",
      "[60 70 80] 90\n",
      "[70 80 90] 100\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "\n",
    "def split_sequence(sequence, n_steps):\n",
    "    x,y = list(),list()\n",
    "    for i in range(len(sequence)):\n",
    "        end_ix = i + n_steps\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        seq_x,seq_y = sequence[i:end_ix] , sequence[end_ix]\n",
    "        x.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(x), array(y)\n",
    "\n",
    "raw_seq = [10,20,30,40,50,60,70,80,90,100]\n",
    "n_steps = 3\n",
    "x,y = split_sequence(raw_seq,n_steps)\n",
    "for i in range(len(x)):\n",
    "    print(x[i],y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55223b8f",
   "metadata": {},
   "source": [
    "# MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14d154bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 09:21:49.721790: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-06 09:21:49.831242: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-06 09:21:49.834717: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib\n",
      "2023-03-06 09:21:49.834728: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-06 09:21:49.851628: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-06 09:21:50.158704: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib\n",
      "2023-03-06 09:21:50.158750: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib\n",
      "2023-03-06 09:21:50.158753: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-06 09:21:50.657346: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib\n",
      "2023-03-06 09:21:50.657366: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-06 09:21:50.657378: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (adzavon-Latitude-5420): /proc/driver/nvidia/version does not exist\n",
      "2023-03-06 09:21:50.657524: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[100.2191]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define model\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation = \"relu\", input_dim = n_steps))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam',loss=\"mse\")\n",
    "\n",
    "# fit the model\n",
    "\n",
    "model.fit(x,y, epochs=2000,verbose=0)\n",
    "\n",
    "# demonstrate a prediction\n",
    "\n",
    "x_input = array([70,80,90])\n",
    "x_input = x_input.reshape((1,n_steps))\n",
    "y_hat = model.predict(x_input,verbose=0)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8666173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "603fd477",
   "metadata": {},
   "source": [
    "# Multivariate MLP Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392c0519",
   "metadata": {},
   "source": [
    "# 1 - Multivariate MLP Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c71bdf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# deffine the input seq\n",
    "\n",
    "in_seq1 = array([10,20,30,40,50,60,70,80,90])\n",
    "in_seq2 = array([15,25,35,45,55,65,75,85,95])\n",
    "out_seq = array([in_seq1[i] + in_seq2[i] for i in range(len(in_seq1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ac90c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 10  15  25]\n",
      " [ 20  25  45]\n",
      " [ 30  35  65]\n",
      " [ 40  45  85]\n",
      " [ 50  55 105]\n",
      " [ 60  65 125]\n",
      " [ 70  75 145]\n",
      " [ 80  85 165]\n",
      " [ 90  95 185]]\n"
     ]
    }
   ],
   "source": [
    "# cenvert to [row, columns] structure \n",
    "\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "\n",
    "\n",
    "in_seq1 = in_seq1.reshape(len(in_seq1),1)\n",
    "in_seq2 = in_seq2.reshape(len(in_seq2),1)\n",
    "out_seq = out_seq.reshape(len(out_seq),1)\n",
    "\n",
    "# make it horizontal stack column\n",
    "\n",
    "dataset = hstack((in_seq1,in_seq2,out_seq))\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "925a9f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 3) (7,)\n",
      "[[10 15]\n",
      " [20 25]\n",
      " [30 35]] 65\n",
      "[[20 25]\n",
      " [30 35]\n",
      " [40 45]] 85\n",
      "[[30 35]\n",
      " [40 45]\n",
      " [50 55]] 105\n",
      "[[40 45]\n",
      " [50 55]\n",
      " [60 65]] 125\n",
      "[[50 55]\n",
      " [60 65]\n",
      " [70 75]] 145\n",
      "[[60 65]\n",
      " [70 75]\n",
      " [80 85]] 165\n",
      "[[70 75]\n",
      " [80 85]\n",
      " [90 95]] 185\n"
     ]
    }
   ],
   "source": [
    "# multivariate sequence into samples\n",
    "\n",
    "def split_sequence(sequence,n_steps):\n",
    "    x, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        end_x = i + n_steps\n",
    "        \n",
    "        if end_x > len(sequence):\n",
    "            break\n",
    "        seq_x, seq_y = sequence[i:end_x, :-1], sequence[end_x-1,-1]\n",
    "        x.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(x), array(y)\n",
    "\n",
    "dataset = hstack((in_seq1,in_seq2,out_seq))\n",
    "n_steps = 3\n",
    "print(x.shape,y.shape)\n",
    "x,y = split_sequence(dataset, n_steps)\n",
    "for i in range(len(y)):\n",
    "    print(x[i],y[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f00b6672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten the input \n",
    "\n",
    "n_input = x.shape[1] * x.shape[2]\n",
    "x = x.reshape(x.shape[0],n_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66f24959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the moel\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation = \"relu\", input_dim = n_input))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam',loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "623aee2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[206.31926]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the moedl\n",
    "model.fit(x,y, epochs=2000,verbose=0)\n",
    "\n",
    "\n",
    "# demonstrate the prediction\n",
    "\n",
    "x_input = array([[80,85],[90,95],[100,105]])\n",
    "x_input = x_input.reshape(1,n_input)\n",
    "y_hat = model.predict(x_input,verbose=0)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327242d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8f1f8d9",
   "metadata": {},
   "source": [
    "Multi-headed MLP Model                                                                                                                   \n",
    "\n",
    "There is another more elaborate way to model the problem. Each input series can be handled by\n",
    "a separate MLP and the output of each of these submodels can be combined before a prediction\n",
    "is made for the output sequence. We can refer to this as a multi-headed input MLP model. It\n",
    "may offer more flexibility or better performance depending on the specifics of the problem that\n",
    "are being modeled. This type of model can be defined in Keras using the Keras functional API.\n",
    "First, we can define the first input model as an MLP with an input layer that expects vectors\n",
    "with n steps features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72070a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[205.8012]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from keras.layers import Input\n",
    "from keras.layers import concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "\n",
    "def split_sequence(sequence,n_steps):\n",
    "    x,y = list(),list()\n",
    "    for i in range(len(sequence)):\n",
    "        end_x = i + n_steps\n",
    "        if end_x > len(sequence):\n",
    "            break\n",
    "        seq_x, seq_y = sequence[i:end_x,:-1], sequence[end_x-1,-1]\n",
    "        x.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(x), array(y)\n",
    "\n",
    "# define input sequenceabs\n",
    "\n",
    "in_seq1 = array([10,20,30,40,50,60,70,80,90])\n",
    "in_seq2 = array([15,25,35,45,55,65,75,85,95])\n",
    "out_seq = array([in_seq1[i] + in_seq2[i] \n",
    "                 for i in range(len(in_seq1))])\n",
    "\n",
    "# convert to [row,columns] structure\n",
    "in_seq1 = in_seq1.reshape(len(in_seq1),1)\n",
    "in_seq2 = in_seq2.reshape(len(in_seq2),1)\n",
    "out_seq = out_seq.reshape(len(out_seq),1)\n",
    "\n",
    "#horizontal stack column\n",
    "\n",
    "dataset = hstack((in_seq1,in_seq2,out_seq))\n",
    "\n",
    "# number of time steps\n",
    "n_steps = 3\n",
    "\n",
    "# convert into input output\n",
    "x,y = split_sequence(dataset,n_steps)\n",
    "\n",
    "# #separate input data\n",
    "x1 = x[:,:,0]\n",
    "x2 = x[:,:,1]\n",
    "\n",
    "# first input model\n",
    "# first input model\n",
    "visible1 = Input(shape=(n_steps,))\n",
    "dense1 = Dense(100, activation='relu')(visible1)\n",
    "# second input model\n",
    "visible2 = Input(shape=(n_steps,))\n",
    "dense2 = Dense(100, activation='relu')(visible2)\n",
    "# merge input models\n",
    "merge = concatenate([dense1, dense2])\n",
    "output = Dense(1)(merge)\n",
    "model = Model(inputs=[visible1, visible2], outputs=output)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model.fit([x1, x2], y, epochs=2000, verbose=0)\n",
    "# demonstrate prediction\n",
    "x_input = array([[80, 85], [90, 95], [100, 105]])\n",
    "x1 = x_input[:, 0].reshape((1, n_steps))\n",
    "x2 = x_input[:, 1].reshape((1, n_steps))\n",
    "yhat = model.predict([x1, x2], verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaa0a45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75b4bb71",
   "metadata": {},
   "source": [
    "# 2 - Multiple Parallel Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3b546db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 3, 3) (6, 3)\n",
      "[[10 15 25]\n",
      " [20 25 45]\n",
      " [30 35 65]] [40 45 85]\n",
      "[[20 25 45]\n",
      " [30 35 65]\n",
      " [40 45 85]] [ 50  55 105]\n",
      "[[ 30  35  65]\n",
      " [ 40  45  85]\n",
      " [ 50  55 105]] [ 60  65 125]\n",
      "[[ 40  45  85]\n",
      " [ 50  55 105]\n",
      " [ 60  65 125]] [ 70  75 145]\n",
      "[[ 50  55 105]\n",
      " [ 60  65 125]\n",
      " [ 70  75 145]] [ 80  85 165]\n",
      "[[ 60  65 125]\n",
      " [ 70  75 145]\n",
      " [ 80  85 165]] [ 90  95 185]\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from keras.layers import Input\n",
    "from keras.layers import concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "def split_sequence(sequence,n_steps):\n",
    "    x,y = list(),list()\n",
    "    for i in range(len(sequence)):\n",
    "        end_x = i + n_steps\n",
    "        if end_x > len(sequence)-1:\n",
    "            break\n",
    "        seq_x, seq_y = sequence[i:end_x,:], sequence[end_x,:]\n",
    "        x.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(x), array(y)\n",
    "\n",
    "# define input sequenceabs\n",
    "\n",
    "in_seq1 = array([10,20,30,40,50,60,70,80,90])\n",
    "in_seq2 = array([15,25,35,45,55,65,75,85,95])\n",
    "out_seq = array([in_seq1[i] + in_seq2[i] \n",
    "                 for i in range(len(in_seq1))])\n",
    "\n",
    "# convert to [row,columns] structure\n",
    "in_seq1 = in_seq1.reshape(len(in_seq1),1)\n",
    "in_seq2 = in_seq2.reshape(len(in_seq2),1)\n",
    "out_seq = out_seq.reshape(len(out_seq),1)\n",
    "\n",
    "#horizontal stack column\n",
    "\n",
    "dataset = hstack((in_seq1,in_seq2,out_seq))\n",
    "\n",
    "# number of time steps\n",
    "n_steps = 3\n",
    "\n",
    "# convert into input output\n",
    "x,y = split_sequence(dataset,n_steps)\n",
    "\n",
    "print(x.shape,y.shape)\n",
    "\n",
    "# summarizing the data\n",
    "for i in range(len(x)):\n",
    "    print(x[i],y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5afdfb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten input\n",
    "n_input = x.shape[1] * x.shape[2]\n",
    "x = x.reshape((x.shape[0],n_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a05df79",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_output = y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "665eaab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation=\"relu\",input_dim = n_input))\n",
    "model.add(Dense(n_output))\n",
    "model.compile(optimizer=\"adam\",loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f833d4e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f08fbfc6580>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "\n",
    "model.fit(x,y,epochs=200,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75b12d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[106.74658 115.66115 220.84004]]\n"
     ]
    }
   ],
   "source": [
    "# demonstrate prediction\n",
    "\n",
    "x_input = array([[70,75,145], [80,85,165], [90,95,185]])\n",
    "x_input = x_input.reshape((1, n_input))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db665e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3cbcb148",
   "metadata": {},
   "source": [
    "Multi-output MLP Model\n",
    "\n",
    "\n",
    "As with multiple input series, there is another, more elaborate way to model the problem. Each\n",
    "output series can be handled by a separate output MLP model. We can refer to this as a\n",
    "multi-output MLP model. It may offer more flexibility or better performance depending on the\n",
    "specifics of the problem that is being modeled. This type of model can be defined in Keras\n",
    "using the Keras functional API. First, we can define the input model as an MLP with an input\n",
    "layer that expects flattened feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd14e4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multivariate output mlp example\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps):\n",
    "    x, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the dataset\n",
    "        if end_ix > len(sequences)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix, :]\n",
    "        x.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(x), array(y)\n",
    "# define input sequence\n",
    "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
    "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
    "# convert to [rows, columns] structure\n",
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "# horizontally stack columns\n",
    "dataset = hstack((in_seq1, in_seq2, out_seq))\n",
    "# choose a number of time steps\n",
    "n_steps = 3\n",
    "# convert into input/output\n",
    "x, y = split_sequences(dataset, n_steps)\n",
    "# flatten input\n",
    "n_input = x.shape[1] * x.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2dac5c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f09196acee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[array([[100.98739]], dtype=float32), array([[105.49902]], dtype=float32), array([[206.69803]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "x = x.reshape((x.shape[0], n_input))\n",
    "# separate output\n",
    "y1 = y[:, 0].reshape((y.shape[0], 1))\n",
    "y2 = y[:, 1].reshape((y.shape[0], 1))\n",
    "y3 = y[:, 2].reshape((y.shape[0], 1))\n",
    "# define model\n",
    "visible = Input(shape=(n_input,))\n",
    "dense = Dense(100, activation='relu')(visible)\n",
    "# define output 1\n",
    "output1 = Dense(1)(dense)\n",
    "# define output 2\n",
    "output2 = Dense(1)(dense)\n",
    "# define output 2\n",
    "output3 = Dense(1)(dense)\n",
    "# tie together\n",
    "model = Model(inputs=visible, outputs=[output1, output2, output3])\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model.fit(x, [y1,y2,y3], epochs=2000, verbose=0)\n",
    "# demonstrate prediction\n",
    "x_input = array([[70,75,145], [80,85,165], [90,95,185]])\n",
    "x_input = x_input.reshape((1, n_input))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137e7055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "066aec47",
   "metadata": {},
   "source": [
    "# Multi-step MLP Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97eddffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 20 30] [40 50]\n",
      "[20 30 40] [50 60]\n",
      "[30 40 50] [60 70]\n",
      "[40 50 60] [70 80]\n",
      "[50 60 70] [80 90]\n"
     ]
    }
   ],
   "source": [
    "from numpy import array \n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "\n",
    "def split_sequence(sequence, n_steps_in, n_steps_out):\n",
    "    x,y = list(),list()\n",
    "    for i in range(len(sequence)):\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        \n",
    "        if out_end_ix > len(sequence):\n",
    "            break\n",
    "        seq_x, seq_y = sequence[i:end_ix] , sequence[end_ix:out_end_ix]\n",
    "        x.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(x), array(y)\n",
    "\n",
    "raw_seq = [10,20,30,40,50,60,70,80,90]\n",
    "\n",
    "n_steps_in, n_steps_out = 3,2\n",
    "\n",
    "x,y = split_sequence(raw_seq,n_steps_in,n_steps_out)\n",
    "\n",
    "for i in range(len(x)):\n",
    "    print(x[i],y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5fffe18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100,activation=\"relu\",input_dim = n_steps_in))\n",
    "model.add(Dense(n_steps_out))\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "103b34ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f09196a4d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "\n",
    "model.fit(x,y, epochs=2000, verbose=0)\n",
    "\n",
    "# demonstrate prediction\n",
    "\n",
    "x_input = array([70,80,90])\n",
    "x_input = x_input.reshape(1,n_steps_in)\n",
    "yhat = model.predict(x_input,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "430139ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100.392006 110.86723 ]]\n"
     ]
    }
   ],
   "source": [
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17aee29f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85b4145e",
   "metadata": {},
   "source": [
    "# How to Develop CNNs for Time Series Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f6e4cf",
   "metadata": {},
   "source": [
    "# Univariate CNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a869ef22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 20 30] 40\n",
      "[20 30 40] 50\n",
      "[30 40 50] 60\n",
      "[40 50 60] 70\n",
      "[50 60 70] 80\n",
      "[60 70 80] 90\n"
     ]
    }
   ],
   "source": [
    "def split_sequence(sequence,n_steps):\n",
    "    x,y = list(),list()\n",
    "    for i in range(len(sequence)):\n",
    "        end_ix = i + n_steps\n",
    "        \n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        seq_x, seq_y = sequence[i:end_ix] , sequence[end_ix]\n",
    "        x.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "        \n",
    "    return array(x), array(y)\n",
    "\n",
    "sequence = [10,20,30,40,50,60,70,80,90]\n",
    "n_steps = 3\n",
    "x,y = split_sequence(sequence,n_steps)\n",
    "for i in range(len(x)):\n",
    "    print(x[i],y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7610d77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[10],\n",
       "        [20],\n",
       "        [30]],\n",
       "\n",
       "       [[20],\n",
       "        [30],\n",
       "        [40]],\n",
       "\n",
       "       [[30],\n",
       "        [40],\n",
       "        [50]],\n",
       "\n",
       "       [[40],\n",
       "        [50],\n",
       "        [60]],\n",
       "\n",
       "       [[50],\n",
       "        [60],\n",
       "        [70]],\n",
       "\n",
       "       [[60],\n",
       "        [70],\n",
       "        [80]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "\n",
    "n_features = 1\n",
    "x = x.reshape(x.shape[0],x.shape[1],n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0767ed1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 11:16:57.679585: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-06 11:16:57.765313: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-06 11:16:57.768789: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib\n",
      "2023-03-06 11:16:57.768799: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-06 11:16:57.785737: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-06 11:16:58.148900: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib\n",
      "2023-03-06 11:16:58.148947: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib\n",
      "2023-03-06 11:16:58.148951: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-06 11:16:58.666739: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib\n",
      "2023-03-06 11:16:58.666760: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-06 11:16:58.666773: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (adzavon-Latitude-5420): /proc/driver/nvidia/version does not exist\n",
      "2023-03-06 11:16:58.666925: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'n_steps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_54079/2338525833.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#                  input_shape=(n_steps,n_features)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# model.add(MaxPooling1D())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n_steps' is not defined"
     ]
    }
   ],
   "source": [
    "# define the model \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import conv1d\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.convolutional import Conv1D\n",
    "\n",
    "model = Sequential()\n",
    "# model.add(conv1d(64,2,\n",
    "#                  activation=\"relu\",\n",
    "#                  input_shape=(n_steps,n_features)))\n",
    "# model.add(MaxPooling1D())\n",
    "model.add(Conv1D(64, 2, activation='relu', input_shape=(n_steps, n_features)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50,activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"adam\",loss = \"mse\")\n",
    "\n",
    "# model fit\n",
    "\n",
    "model.fit(x,y,epochs=1000, verbose=0)\n",
    "\n",
    "# Demonstrate prediction\n",
    "\n",
    "x_input = array([70,80,90])\n",
    "x_input = x_input.reshape(1,n_steps,n_features)\n",
    "y_hat = model.predict(x_input,verbose=0)\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217ae273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a799bd05",
   "metadata": {},
   "source": [
    "# Multivariate CNN Models\n",
    "Multiple Input Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56e23e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10 15]\n",
      " [20 25]\n",
      " [30 35]] 65\n",
      "[[20 25]\n",
      " [30 35]\n",
      " [40 45]] 85\n",
      "[[30 35]\n",
      " [40 45]\n",
      " [50 55]] 105\n",
      "[[40 45]\n",
      " [50 55]\n",
      " [60 65]] 125\n",
      "[[50 55]\n",
      " [60 65]\n",
      " [70 75]] 145\n",
      "[[60 65]\n",
      " [70 75]\n",
      " [80 85]] 165\n",
      "[[70 75]\n",
      " [80 85]\n",
      " [90 95]] 185\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy import hstack\n",
    "\n",
    "\n",
    "def split_sequence(sequence,n_steps):\n",
    "    x,y = list(),list()\n",
    "    for i in range(len(sequence)):\n",
    "        end_ix = i + n_steps\n",
    "        if end_ix > len(sequence):\n",
    "            break\n",
    "        seq_x, seq_y = sequence[i:end_ix, :-1], sequence[end_ix-1,-1]\n",
    "        x.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(x),array(y)\n",
    "\n",
    "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
    "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
    "\n",
    "# convert to [rows, columns] structure\n",
    "\n",
    "in_seq1 = in_seq1.reshape(len(in_seq1),1)\n",
    "in_seq2 = in_seq2.reshape(len(in_seq2),1)\n",
    "out_seq = out_seq.reshape(len(out_seq),1)\n",
    "dataset = hstack((in_seq1,in_seq2,out_seq))\n",
    "\n",
    "# choose a number of time steps\n",
    "n_steps = 3\n",
    "\n",
    "# convert into input output\n",
    "\n",
    "x,y = split_sequence(dataset,n_steps)\n",
    "\n",
    "for i in range(len(x)):\n",
    "    print(x[i], y[i])\n",
    "    \n",
    "n_features = x.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ae10674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[208.58894]]\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "n_features = x.shape[2]\n",
    "model.add(Conv1D(64, 2, \n",
    "                 activation='relu',\n",
    "                 input_shape=(n_steps, n_features)))\n",
    "\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model.fit(x, y, epochs=1000, verbose=0)\n",
    "# demonstrate prediction\n",
    "x_input = array([[80, 85], [90, 95], [100, 105]])\n",
    "x_input = x_input.reshape((1, n_steps, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a991fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c77474f7",
   "metadata": {},
   "source": [
    "# Multi-step CNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a77cef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101.555916 101.59334 ]]\n"
     ]
    }
   ],
   "source": [
    "# univariate multi-step vector-output 1d cnn example\n",
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        # check if we are beyond the sequence\n",
    "        if out_end_ix > len(sequence):\n",
    "            break\n",
    "    # gather input and output parts of the pattern\n",
    "    seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
    "    X.append(seq_x)\n",
    "    y.append(seq_y)\n",
    "    return array(X), array(y)\n",
    "# define input sequence\n",
    "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out = 3, 2\n",
    "# split into samples\n",
    "X, y = split_sequence(raw_seq, n_steps_in, n_steps_out)\n",
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "# split into samples\n",
    "X, y = split_sequence(raw_seq, n_steps_in, n_steps_out)\n",
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(64, 2, activation='relu', input_shape=(n_steps_in, n_features)))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(n_steps_out))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model.fit(X, y, epochs=2000, verbose=0)\n",
    "# demonstrate prediction\n",
    "x_input = array([70, 80, 90])\n",
    "x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f538027",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6470096",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa6e24fe",
   "metadata": {},
   "source": [
    "# How to Develop LSTMs for Time Series Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f26751",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
